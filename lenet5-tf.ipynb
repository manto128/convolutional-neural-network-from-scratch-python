{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 00:21:25.962693: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import datasets, layers, models, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "(train_images, train_labels), (test_images, test_labels)= datasets.mnist.load_data()\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([60000, 32, 32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad input 28x28 images with zeros to 32x32 images and scaled 8-bit pixel values to values between 0-1\n",
    "train_images = tf.pad(train_images, [[0, 0], [2,2], [2,2]])\n",
    "test_images = tf.pad(test_images, [[0, 0], [2,2], [2,2]])\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([60000, 32, 32, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = tf.expand_dims(train_images, axis=3, name=None)\n",
    "test_images = tf.expand_dims(test_images, axis=3, name=None)\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = train_images[-2000:,:,:,:] \n",
    "val_labels = train_labels[-2000:] \n",
    "train_images = train_images[:-2000,:,:,:] \n",
    "train_labels = train_labels[:-2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 6)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 16)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 1, 1, 120)         48120     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 120)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61706 (241.04 KB)\n",
      "Trainable params: 61706 (241.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(6, 5, activation='relu6', input_shape=train_images.shape[1:]))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "# model.add(layers.Activation('sigmoid'))\n",
    "model.add(layers.Conv2D(16, 5, activation='relu6'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "# model.add(layers.Activation('sigmoid'))\n",
    "model.add(layers.Conv2D(120, 5, activation='relu6'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(84, activation='relu6'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "907/907 [==============================] - 13s 14ms/step - loss: 0.2123 - accuracy: 0.9338 - val_loss: 0.0650 - val_accuracy: 0.9830\n",
      "Epoch 2/10\n",
      "907/907 [==============================] - 13s 15ms/step - loss: 0.0748 - accuracy: 0.9761 - val_loss: 0.0472 - val_accuracy: 0.9865\n",
      "Epoch 3/10\n",
      "907/907 [==============================] - 14s 16ms/step - loss: 0.0588 - accuracy: 0.9810 - val_loss: 0.0469 - val_accuracy: 0.9865\n",
      "Epoch 4/10\n",
      "907/907 [==============================] - 13s 15ms/step - loss: 0.0446 - accuracy: 0.9854 - val_loss: 0.0438 - val_accuracy: 0.9880\n",
      "Epoch 5/10\n",
      "907/907 [==============================] - 13s 15ms/step - loss: 0.0442 - accuracy: 0.9858 - val_loss: 0.0493 - val_accuracy: 0.9850\n",
      "Epoch 6/10\n",
      "907/907 [==============================] - 15s 16ms/step - loss: 0.0362 - accuracy: 0.9881 - val_loss: 0.0368 - val_accuracy: 0.9915\n",
      "Epoch 7/10\n",
      "907/907 [==============================] - 15s 16ms/step - loss: 0.0348 - accuracy: 0.9883 - val_loss: 0.0372 - val_accuracy: 0.9915\n",
      "Epoch 8/10\n",
      "907/907 [==============================] - 15s 17ms/step - loss: 0.0294 - accuracy: 0.9899 - val_loss: 0.0577 - val_accuracy: 0.9865\n",
      "Epoch 9/10\n",
      "907/907 [==============================] - 15s 17ms/step - loss: 0.0261 - accuracy: 0.9910 - val_loss: 0.0390 - val_accuracy: 0.9905\n",
      "Epoch 10/10\n",
      "907/907 [==============================] - 15s 17ms/step - loss: 0.0265 - accuracy: 0.9910 - val_loss: 0.0433 - val_accuracy: 0.9905\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss=losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "history = model.fit(train_images, train_labels, batch_size=64, epochs=10, validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):\n",
    "        # Model has only one input so each data point has one element.\n",
    "        yield [tf.dtypes.cast(input_value, tf.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/xs/nn2f1m4d4vg3mp72k2gv6c8h0000gn/T/tmpb94q_6u2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/xs/nn2f1m4d4vg3mp72k2gv6c8h0000gn/T/tmpb94q_6u2/assets\n",
      "/Users/abhishek/Desktop/PhD/Research/ML_and_AI/Models/src/lenet-from-scratch/.venv/lib/python3.11/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-02-29 12:40:07.033486: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-02-29 12:40:07.033503: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-02-29 12:40:07.033769: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/xs/nn2f1m4d4vg3mp72k2gv6c8h0000gn/T/tmpb94q_6u2\n",
      "2024-02-29 12:40:07.036329: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-02-29 12:40:07.036382: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/xs/nn2f1m4d4vg3mp72k2gv6c8h0000gn/T/tmpb94q_6u2\n",
      "2024-02-29 12:40:07.043364: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-02-29 12:40:07.127177: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/xs/nn2f1m4d4vg3mp72k2gv6c8h0000gn/T/tmpb94q_6u2\n",
      "2024-02-29 12:40:07.154174: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 120405 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 11, Total Ops 23, % non-converted = 47.83 %\n",
      " * 11 ARITH ops\n",
      "\n",
      "- arith.constant:   11 occurrences  (f32: 10, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 3)\n",
      "  (f32: 2)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "tflite_quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.int8'>\n",
      "output:  <class 'numpy.int8'>\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tflite_quant_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Save the quantized model:\u001b[39;00m\n\u001b[1;32m     11\u001b[0m tflite_model_quant_file \u001b[38;5;241m=\u001b[39m tflite_models_dir\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlenet5_int8.tflite\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 12\u001b[0m tflite_model_quant_file\u001b[38;5;241m.\u001b[39mwrite_bytes(\u001b[43mtflite_quant_model\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tflite_quant_model' is not defined"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "tflite_models_dir = pathlib.Path(\"../../saved_models\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save the unquantized model:\n",
    "tf_model_file = tflite_models_dir/\"lenet5.keras\"\n",
    "model.save(tf_model_file)\n",
    "\n",
    "# Save the quantized model:\n",
    "tflite_model_quant_file = tflite_models_dir/\"lenet5_int8.tflite\"\n",
    "tflite_model_quant_file.write_bytes(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tflite_runtime.interpreter as tflite\n",
    "\n",
    "# Helper function to run inference on a TFLite model\n",
    "def run_tflite_model(tflite_file, test_image_indices):\n",
    "  global test_images\n",
    "\n",
    "  # Initialize the interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  predictions = np.zeros((len(test_image_indices),), dtype=np.int32)\n",
    "  for i, test_image_index in enumerate(test_image_indices):\n",
    "    test_image = test_images[test_image_index]\n",
    "\n",
    "    # Check if the input type is quantized, then rescale test data to int8\n",
    "    if input_details['dtype'] == tf.int8:\n",
    "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "      # print(input_scale, input_zero_point)\n",
    "      test_image = tf.clip_by_value(tf.round(tf.cast(test_image, dtype=tf.float32) / input_scale) + input_zero_point, clip_value_min=-128, clip_value_max=127)\n",
    "\n",
    "    # print(test_image.shape)\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "    # print(test_image.shape)\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to evaluate a TFLite model on all images\n",
    "def evaluate_model(tflite_file, model_type):\n",
    "  global test_images\n",
    "  global test_labels\n",
    "\n",
    "  test_image_indices = range(test_images.shape[0])\n",
    "  predictions = run_tflite_model(tflite_file, test_image_indices)\n",
    "\n",
    "  accuracy = (np.sum(test_labels== predictions) * 100) / len(test_images)\n",
    "\n",
    "  print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (\n",
    "      model_type, accuracy, len(test_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int8 model accuracy is 98.4100% (Number of test samples=10000)\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(tflite_model_quant_file, model_type=\"Int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'serving_default_conv2d_input:0', 'index': 0, 'shape': array([ 1, 32, 32,  1], dtype=int32), 'shape_signature': array([-1, 32, 32,  1], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (1.0, -128), 'quantization_parameters': {'scales': array([1.], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'sequential/flatten/Const', 'index': 1, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'sequential/dense_1/BiasAdd/ReadVariableOp', 'index': 2, 'shape': array([10], dtype=int32), 'shape_signature': array([10], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.00011738256580429152, 0), 'quantization_parameters': {'scales': array([0.00011738], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'sequential/dense_1/MatMul', 'index': 3, 'shape': array([10, 84], dtype=int32), 'shape_signature': array([10, 84], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.004988758824765682, 0), 'quantization_parameters': {'scales': array([0.00498876], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'sequential/dense/BiasAdd/ReadVariableOp', 'index': 4, 'shape': array([84], dtype=int32), 'shape_signature': array([84], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (9.678636706667021e-05, 0), 'quantization_parameters': {'scales': array([9.678637e-05], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'sequential/dense/MatMul', 'index': 5, 'shape': array([ 84, 120], dtype=int32), 'shape_signature': array([ 84, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.004113420378416777, 0), 'quantization_parameters': {'scales': array([0.00411342], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'sequential/conv2d_2/BiasAdd/ReadVariableOp', 'index': 6, 'shape': array([120], dtype=int32), 'shape_signature': array([120], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.18795060e-05, 2.99790663e-05, 1.92092739e-05, 5.30794423e-05,\n",
      "       1.31457446e-05, 2.18641435e-05, 1.32218702e-05, 7.60599141e-05,\n",
      "       6.44925312e-05, 4.89716222e-05, 1.20467903e-05, 4.58423929e-05,\n",
      "       5.33092134e-05, 1.20466848e-05, 1.01522874e-05, 1.72673736e-05,\n",
      "       5.02404291e-05, 1.28586380e-05, 5.86595525e-05, 6.18478443e-05,\n",
      "       4.61770433e-05, 5.90154814e-05, 4.80611343e-05, 6.35403849e-05,\n",
      "       5.77313185e-05, 1.54509180e-05, 5.42217640e-05, 1.91816380e-05,\n",
      "       4.55064110e-05, 5.01785871e-05, 3.46743072e-05, 5.35180152e-05,\n",
      "       1.12437137e-05, 5.81100358e-05, 5.45891053e-05, 5.47267191e-05,\n",
      "       5.12459264e-05, 4.86840399e-05, 1.43541656e-05, 3.48868052e-05,\n",
      "       6.90984016e-05, 6.62196690e-05, 1.34034426e-05, 3.07162300e-05,\n",
      "       6.40477301e-05, 5.97458165e-05, 6.85970954e-05, 6.35851975e-05,\n",
      "       5.42512898e-05, 4.33095811e-05, 4.85894998e-05, 5.34639003e-05,\n",
      "       4.25721591e-05, 2.46515920e-05, 6.51511364e-05, 6.16876277e-05,\n",
      "       6.59573852e-05, 1.00207799e-05, 5.03844167e-05, 1.40105485e-05,\n",
      "       4.70492123e-05, 1.25292545e-05, 6.55141630e-05, 4.72386928e-05,\n",
      "       4.99875132e-05, 4.19314347e-05, 1.38519990e-05, 1.40208422e-05,\n",
      "       4.96916437e-05, 4.54774890e-05, 1.36382760e-05, 1.05856006e-05,\n",
      "       1.54129702e-05, 1.19897968e-05, 4.92177787e-05, 5.07167388e-05,\n",
      "       5.64693910e-05, 1.38848845e-05, 5.36500011e-05, 7.40984688e-05,\n",
      "       5.08057055e-05, 5.51449484e-05, 4.82005780e-05, 5.02828261e-05,\n",
      "       1.18119533e-05, 1.03227267e-05, 4.99872513e-05, 4.49547188e-05,\n",
      "       2.13827316e-05, 5.13587365e-05, 6.22331427e-05, 6.16391917e-05,\n",
      "       6.14671299e-05, 4.63745855e-05, 4.97728543e-05, 5.08190460e-05,\n",
      "       1.10443534e-05, 5.59079235e-05, 2.24220257e-05, 5.35250547e-05,\n",
      "       4.51943888e-05, 9.98332325e-06, 4.47009988e-05, 1.29661921e-05,\n",
      "       1.30752023e-05, 3.77983815e-05, 4.79699229e-05, 5.31999940e-05,\n",
      "       6.42981613e-05, 4.48724350e-05, 5.98226834e-05, 4.97807305e-05,\n",
      "       2.86578870e-05, 4.73501495e-05, 6.40580620e-05, 4.32571724e-05,\n",
      "       3.66659515e-05, 5.41752670e-05, 4.06929648e-05, 2.04491753e-05],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'sequential/conv2d_2/Conv2D', 'index': 7, 'shape': array([120,   5,   5,  16], dtype=int32), 'shape_signature': array([120,   5,   5,  16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00050488, 0.00127411, 0.00081639, 0.00225588, 0.00055869,\n",
      "       0.00092923, 0.00056193, 0.00323255, 0.00274093, 0.00208129,\n",
      "       0.00051199, 0.0019483 , 0.00226564, 0.00051198, 0.00043147,\n",
      "       0.00073386, 0.00213522, 0.00054649, 0.00249303, 0.00262853,\n",
      "       0.00196252, 0.00250816, 0.0020426 , 0.00270047, 0.00245358,\n",
      "       0.00065666, 0.00230442, 0.00081522, 0.00193402, 0.00213259,\n",
      "       0.00147366, 0.00227452, 0.00047786, 0.00246968, 0.00232004,\n",
      "       0.00232589, 0.00217795, 0.00206907, 0.00061005, 0.00148269,\n",
      "       0.00293668, 0.00281434, 0.00056965, 0.00130544, 0.00272203,\n",
      "       0.0025392 , 0.00291538, 0.00270237, 0.00230568, 0.00184066,\n",
      "       0.00206505, 0.00227222, 0.00180932, 0.00104769, 0.00276892,\n",
      "       0.00262172, 0.00280319, 0.00042588, 0.00214134, 0.00059545,\n",
      "       0.00199959, 0.00053249, 0.00278435, 0.00200764, 0.00212447,\n",
      "       0.00178209, 0.00058871, 0.00059589, 0.00211189, 0.00193279,\n",
      "       0.00057963, 0.00044989, 0.00065505, 0.00050957, 0.00209176,\n",
      "       0.00215546, 0.00239995, 0.00059011, 0.00228012, 0.00314918,\n",
      "       0.00215924, 0.00234366, 0.00204852, 0.00213702, 0.00050201,\n",
      "       0.00043872, 0.00212446, 0.00191058, 0.00090877, 0.00218275,\n",
      "       0.00264491, 0.00261967, 0.00261235, 0.00197092, 0.00211535,\n",
      "       0.00215981, 0.00046939, 0.00237609, 0.00095294, 0.00227481,\n",
      "       0.00192076, 0.00042429, 0.00189979, 0.00055106, 0.0005557 ,\n",
      "       0.00160643, 0.00203872, 0.002261  , 0.00273267, 0.00190708,\n",
      "       0.00254246, 0.00211568, 0.00121796, 0.00201238, 0.00272247,\n",
      "       0.00183843, 0.0015583 , 0.00230245, 0.00172945, 0.00086909],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'sequential/conv2d_1/BiasAdd/ReadVariableOp', 'index': 8, 'shape': array([16], dtype=int32), 'shape_signature': array([16], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([7.2613904e-05, 7.1016089e-05, 5.8548056e-05, 6.0356047e-05,\n",
      "       7.7325378e-05, 4.9039503e-05, 6.0252398e-05, 8.1219281e-05,\n",
      "       7.9037818e-05, 6.5403678e-05, 6.0531482e-05, 9.0696900e-05,\n",
      "       6.8728412e-05, 6.2602172e-05, 4.9843267e-05, 5.2526626e-05],\n",
      "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'sequential/conv2d_1/Conv2D', 'index': 9, 'shape': array([16,  5,  5,  6], dtype=int32), 'shape_signature': array([16,  5,  5,  6], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00308609, 0.00301818, 0.00248829, 0.00256513, 0.00328633,\n",
      "       0.00208418, 0.00256073, 0.00345182, 0.00335911, 0.00277966,\n",
      "       0.00257259, 0.00385462, 0.00292096, 0.00266059, 0.00211834,\n",
      "       0.00223238], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'sequential/conv2d/BiasAdd/ReadVariableOp', 'index': 10, 'shape': array([6], dtype=int32), 'shape_signature': array([6], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00341544, 0.00208532, 0.00211093, 0.00245077, 0.00222572,\n",
      "       0.00232145], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'sequential/conv2d/Conv2D', 'index': 11, 'shape': array([6, 5, 5, 1], dtype=int32), 'shape_signature': array([6, 5, 5, 1], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00341544, 0.00208532, 0.00211093, 0.00245077, 0.00222572,\n",
      "       0.00232145], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'sequential/conv2d/Relu6;sequential/conv2d/BiasAdd;sequential/conv2d/Conv2D;sequential/conv2d/BiasAdd/ReadVariableOp', 'index': 12, 'shape': array([ 1, 28, 28,  6], dtype=int32), 'shape_signature': array([-1, 28, 28,  6], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0235294122248888, -128), 'quantization_parameters': {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'sequential/max_pooling2d/MaxPool', 'index': 13, 'shape': array([ 1, 14, 14,  6], dtype=int32), 'shape_signature': array([-1, 14, 14,  6], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0235294122248888, -128), 'quantization_parameters': {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'sequential/conv2d_1/Relu6;sequential/conv2d_1/BiasAdd;sequential/conv2d_1/Conv2D;sequential/conv2d_1/BiasAdd/ReadVariableOp', 'index': 14, 'shape': array([ 1, 10, 10, 16], dtype=int32), 'shape_signature': array([-1, 10, 10, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0235294122248888, -128), 'quantization_parameters': {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'sequential/max_pooling2d_1/MaxPool', 'index': 15, 'shape': array([ 1,  5,  5, 16], dtype=int32), 'shape_signature': array([-1,  5,  5, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0235294122248888, -128), 'quantization_parameters': {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'sequential/conv2d_2/Relu6;sequential/conv2d_2/BiasAdd;sequential/conv2d_2/Conv2D;sequential/conv2d_2/BiasAdd/ReadVariableOp', 'index': 16, 'shape': array([  1,   1,   1, 120], dtype=int32), 'shape_signature': array([ -1,   1,   1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0235294122248888, -128), 'quantization_parameters': {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'sequential/flatten/Reshape', 'index': 17, 'shape': array([  1, 120], dtype=int32), 'shape_signature': array([ -1, 120], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0235294122248888, -128), 'quantization_parameters': {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'sequential/dense/MatMul;sequential/dense/Relu6;sequential/dense/BiasAdd', 'index': 18, 'shape': array([ 1, 84], dtype=int32), 'shape_signature': array([-1, 84], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0235294122248888, -128), 'quantization_parameters': {'scales': array([0.02352941], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'sequential/dense_1/MatMul;sequential/dense_1/BiasAdd', 'index': 19, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([-1, 10], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.11334472894668579, -12), 'quantization_parameters': {'scales': array([0.11334473], dtype=float32), 'zero_points': array([-12], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': 'StatefulPartitionedCall:0', 'index': 20, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([-1, 10], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00390625, -128), 'quantization_parameters': {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': '', 'index': 33, 'shape': array([ 1, 28, 28, 25], dtype=int32), 'shape_signature': array([ 1, 28, 28, 25], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': '', 'index': 34, 'shape': array([  1,  10,  10, 150], dtype=int32), 'shape_signature': array([  1,  10,  10, 150], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "{'name': '', 'index': 35, 'shape': array([  1,   1,   1, 400], dtype=int32), 'shape_signature': array([  1,   1,   1, 400], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "tflite_interpreter = tf.lite.Interpreter(model_path=str(tflite_model_quant_file))\n",
    "tflite_interpreter.allocate_tensors()\n",
    "\n",
    "tensor_details = tflite_interpreter.get_tensor_details()\n",
    "num_fc_layers = 2\n",
    "num_conv2d_layers = 3\n",
    "num_reshape_layers = 1\n",
    "\n",
    "obj = []\n",
    "cache = []\n",
    "\n",
    "for dict in tensor_details:\n",
    "    print(dict)\n",
    "    i = dict['index']\n",
    "    name = dict['name']\n",
    "    shape = dict['shape']\n",
    "    if ';' in name:\n",
    "        output_scales = dict['quantization_parameters']['scales']\n",
    "        output_zero_points = dict['quantization_parameters']['zero_points']\n",
    "\n",
    "        if 'Conv2D' in name:\n",
    "            num_conv2d_layers += 1\n",
    "            cache = {'conv' + str(num_conv2d_layers) + '.output.scales': output_scales, 'conv'\n",
    "                     + str(num_conv2d_layers) + '.output.zero_points': output_zero_points}\n",
    "            obj.append(cache)\n",
    "\n",
    "        if 'MatMul' in name:\n",
    "            num_fc_layers += 1\n",
    "            cache = {'fc' + str(num_fc_layers) + '.output.scales': output_scales, 'fc'\n",
    "                     + str(num_fc_layers) + '.output.zero_points': output_zero_points}\n",
    "            obj.append(cache)\n",
    "    else:\n",
    "        if 'input' in name:\n",
    "            input_scales = dict['quantization_parameters']['scales']\n",
    "            input_zero_points = dict['quantization_parameters']['zero_points']\n",
    "            cache = {'input.scales': input_scales, 'input.zero_points': input_zero_points}\n",
    "            obj.append(cache)\n",
    "            # print(name+':')\n",
    "            # print('scales:')\n",
    "            # print(input_scales)\n",
    "            # print('zero_points:')\n",
    "            # print(input_zero_points)\n",
    "\n",
    "        if 'BiasAdd' in name:\n",
    "            bias = tflite_interpreter.tensor(i)()\n",
    "            bias_scales = dict['quantization_parameters']['scales']\n",
    "            bias_zero_points = dict['quantization_parameters']['zero_points']\n",
    "            # print(i, name, shape)\n",
    "            # print(bias)\n",
    "            # print(name+':')\n",
    "            # print('scales:')\n",
    "            # print(bias_scales)\n",
    "            # print('zero_points:')\n",
    "            # print(bias_zero_points)\n",
    "            \n",
    "        if 'MatMul' in name:\n",
    "            weights = tflite_interpreter.tensor(i)()\n",
    "            reshaped_weights = np.transpose(weights)\n",
    "            weight_scales = dict['quantization_parameters']['scales']\n",
    "            weight_zero_points = dict['quantization_parameters']['zero_points']\n",
    "            # print(i, name, reshaped_weights.shape)\n",
    "            # print(reshaped_weights)\n",
    "            cache = {'fc' + str(num_fc_layers) + '.weights': reshaped_weights, 'fc' + str(num_fc_layers) + '.bias': bias,\n",
    "                     'fc' + str(num_fc_layers) + '.weights.scales': weight_scales, 'fc' + str(num_fc_layers) + '.weights.zero_points': weight_zero_points,\n",
    "                     'fc' + str(num_fc_layers) + '.bias.scales': bias_scales, 'fc' + str(num_fc_layers) + '.bias.zero_points': bias_zero_points}\n",
    "            obj.append(cache)\n",
    "            num_fc_layers -= 1\n",
    "            # print(name+':')\n",
    "            # print('scales:')\n",
    "            # print(weight_scales)\n",
    "            # print('zero_points:')\n",
    "            # print(weight_zero_points)\n",
    "\n",
    "        if 'Conv2D' in name:\n",
    "            weights = tflite_interpreter.tensor(i)()\n",
    "            # if num_conv2d_layers == 1:\n",
    "            #     print(i, name, weights.shape)\n",
    "                # print(weights)\n",
    "            reshaped_weights = np.zeros(dtype=np.int8, shape=(weights.shape[0], weights.shape[3], weights.shape[2], weights.shape[1]))\n",
    "            for l in range(weights.shape[0]):\n",
    "                for k in range(weights.shape[1]):\n",
    "                    for j in range(weights.shape[2]):\n",
    "                        for i in range(weights.shape[3]):\n",
    "                            reshaped_weights[l][i][k][j] = weights[l][k][j][i]\n",
    "\n",
    "            weight_scales = dict['quantization_parameters']['scales']\n",
    "            weight_zero_points = dict['quantization_parameters']['zero_points']\n",
    "            # print(name+':')\n",
    "            # print('scales:')\n",
    "            # print(weight_scales)\n",
    "            # print('zero_points:')\n",
    "            # print(weight_zero_points)\n",
    "            \n",
    "            # if num_conv2d_layers == 2:\n",
    "            #     print(i, name, reshaped_weights.shape)\n",
    "            #     print(reshaped_weights)\n",
    "            cache = {'conv' + str(num_conv2d_layers) + '.weights': reshaped_weights, 'conv' + str(num_conv2d_layers) + '.bias': bias,\n",
    "                     'conv' + str(num_conv2d_layers) + '.weights.scales': weight_scales, 'conv' + str(num_conv2d_layers) + '.weights.zero_points': weight_zero_points,\n",
    "                     'conv' + str(num_conv2d_layers) + '.bias.scales': bias_scales, 'conv' + str(num_conv2d_layers) + '.bias.zero_points': bias_zero_points}\n",
    "            obj.append(cache)\n",
    "            num_conv2d_layers -= 1\n",
    "\n",
    "        if 'Reshape' in name:\n",
    "            newshape = dict['shape_signature']\n",
    "            cache = {'reshape' + str(num_reshape_layers) + '.newshape': newshape}\n",
    "            obj.append(cache)\n",
    "            num_reshape_layers -= 1\n",
    "\n",
    "        if 'StatefulPartitionedCall' in name:\n",
    "            output_scales = dict['quantization_parameters']['scales']\n",
    "            output_zero_points = dict['quantization_parameters']['zero_points']\n",
    "            cache = {'softmax.output.scales': output_scales, 'softmax.output.zero_points': output_zero_points}\n",
    "            obj.append(cache)\n",
    "\n",
    "with open('./params.pkl', 'wb') as handle:\n",
    "    pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1, 5, 5) (6,) (1,) (1,) (6,) (6,) (6,) (6,) (1,) (1,)\n",
      "(16, 6, 5, 5) (16,) (16,) (16,) (16,) (16,) (1,) (1,)\n",
      "(120, 16, 5, 5) (120,) (120,) (120,) (120,) (120,) (1,) (1,)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'reshape.newshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 16\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(b[\u001b[38;5;241m4\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2.weights\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, b[\u001b[38;5;241m4\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2.bias\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape,\n\u001b[1;32m      9\u001b[0m       b[\u001b[38;5;241m4\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2.weights.scales\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, b[\u001b[38;5;241m4\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2.weights.zero_points\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape,\n\u001b[1;32m     10\u001b[0m       b[\u001b[38;5;241m4\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2.bias.scales\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, b[\u001b[38;5;241m4\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2.bias.zero_points\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape,\n\u001b[1;32m     11\u001b[0m       b[\u001b[38;5;241m7\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2.output.scales\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, b[\u001b[38;5;241m7\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv2.output.zero_points\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(b[\u001b[38;5;241m3\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv3.weights\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, b[\u001b[38;5;241m3\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv3.bias\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape,\n\u001b[1;32m     13\u001b[0m       b[\u001b[38;5;241m3\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv3.weights.scales\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, b[\u001b[38;5;241m3\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv3.weights.zero_points\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape,\n\u001b[1;32m     14\u001b[0m       b[\u001b[38;5;241m3\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv3.bias.scales\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, b[\u001b[38;5;241m3\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv3.bias.zero_points\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape,\n\u001b[1;32m     15\u001b[0m       b[\u001b[38;5;241m8\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv3.output.scales\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, b[\u001b[38;5;241m8\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv3.output.zero_points\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape.newshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(b[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc1.weights\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, b[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc1.bias\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape,\n\u001b[1;32m     18\u001b[0m       b[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc1.weights.scales\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, b[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc1.weights.zero_points\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape,\n\u001b[1;32m     19\u001b[0m       b[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc1.bias.scales\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, b[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc1.bias.zero_points\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape,\n\u001b[1;32m     20\u001b[0m       b[\u001b[38;5;241m10\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc1.output.scales\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, b[\u001b[38;5;241m10\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc1.output.zero_points\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(b[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc2.weights\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, b[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc2.bias\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape,\n\u001b[1;32m     22\u001b[0m       b[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc2.weights.scales\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, b[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc2.weights.zero_points\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape,\n\u001b[1;32m     23\u001b[0m       b[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc2.bias.scales\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, b[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc2.bias.zero_points\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape,\n\u001b[1;32m     24\u001b[0m       b[\u001b[38;5;241m11\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc2.output.scales\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, b[\u001b[38;5;241m11\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc2.output.zero_points\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'reshape.newshape'"
     ]
    }
   ],
   "source": [
    "with open('./params.pkl', 'rb') as handle:\n",
    "    b = pickle.load(handle)\n",
    "    print(b[5]['conv1.weights'].shape, b[5]['conv1.bias'].shape,\n",
    "          b[0]['input.scales'].shape, b[0]['input.zero_points'].shape,\n",
    "          b[5]['conv1.weights.scales'].shape, b[5]['conv1.weights.zero_points'].shape,\n",
    "          b[5]['conv1.bias.scales'].shape, b[5]['conv1.bias.zero_points'].shape,\n",
    "          b[6]['conv1.output.scales'].shape, b[6]['conv1.output.zero_points'].shape)\n",
    "    print(b[4]['conv2.weights'].shape, b[4]['conv2.bias'].shape,\n",
    "          b[4]['conv2.weights.scales'].shape, b[4]['conv2.weights.zero_points'].shape,\n",
    "          b[4]['conv2.bias.scales'].shape, b[4]['conv2.bias.zero_points'].shape,\n",
    "          b[7]['conv2.output.scales'].shape, b[7]['conv2.output.zero_points'].shape)\n",
    "    print(b[3]['conv3.weights'].shape, b[3]['conv3.bias'].shape,\n",
    "          b[3]['conv3.weights.scales'].shape, b[3]['conv3.weights.zero_points'].shape,\n",
    "          b[3]['conv3.bias.scales'].shape, b[3]['conv3.bias.zero_points'].shape,\n",
    "          b[8]['conv3.output.scales'].shape, b[8]['conv3.output.zero_points'].shape)\n",
    "    print(b[9]['reshape1.newshape'].shape)\n",
    "    print(b[2]['fc1.weights'].shape, b[2]['fc1.bias'].shape,\n",
    "          b[2]['fc1.weights.scales'].shape, b[2]['fc1.weights.zero_points'].shape,\n",
    "          b[2]['fc1.bias.scales'].shape, b[2]['fc1.bias.zero_points'].shape,\n",
    "          b[10]['fc1.output.scales'].shape, b[10]['fc1.output.zero_points'].shape)\n",
    "    print(b[1]['fc2.weights'].shape, b[1]['fc2.bias'].shape,\n",
    "          b[1]['fc2.weights.scales'].shape, b[1]['fc2.weights.zero_points'].shape,\n",
    "          b[1]['fc2.bias.scales'].shape, b[1]['fc2.bias.zero_points'].shape,\n",
    "          b[11]['fc2.output.scales'].shape, b[11]['fc2.output.zero_points'].shape)\n",
    "    print(b[12]['softmax.output.scales'].shape, b[12]['softmax.output.zero_points'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
