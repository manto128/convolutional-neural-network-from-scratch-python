{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# import numpy as np\n",
    "from tensorflow.keras import datasets, layers, models, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "(train_images, train_labels), (test_images, test_labels)= datasets.mnist.load_data()\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad input 28x28 images with zeros to 32x32 images and scaled 8-bit pixel values to values between 0-1\n",
    "train_images = tf.pad(train_images, [[0, 0], [2,2], [2,2]])/255\n",
    "test_images = tf.pad(test_images, [[0, 0], [2,2], [2,2]])\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = tf.expand_dims(train_images, axis=3, name=None)\n",
    "test_images = tf.expand_dims(test_images, axis=3, name=None)\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = train_images[-2000:,:,:,:] \n",
    "val_labels = train_labels[-2000:] \n",
    "train_images = train_images[:-2000,:,:,:] \n",
    "train_labels = train_labels[:-2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(6, 5, activation='relu6', input_shape=train_images.shape[1:]))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "# model.add(layers.Activation('sigmoid'))\n",
    "model.add(layers.Conv2D(16, 5, activation='relu6'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "# model.add(layers.Activation('sigmoid'))\n",
    "model.add(layers.Conv2D(120, 5, activation='relu6'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(84, activation='relu6'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "history = model.fit(train_images, train_labels, batch_size=64, epochs=10, validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):\n",
    "        # Model has only one input so each data point has one element.\n",
    "        yield [input_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "tflite_quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "tflite_models_dir = pathlib.Path(\"../saved_models\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save the unquantized model:\n",
    "tf_model_file = tflite_models_dir/\"lenet5.keras\"\n",
    "model.save(tf_model_file)\n",
    "\n",
    "# Save the quantized model:\n",
    "tflite_model_quant_file = tflite_models_dir/\"lenet5_int8.tflite\"\n",
    "tflite_model_quant_file.write_bytes(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflite_runtime.interpreter as tflite\n",
    "import numpy as np\n",
    "\n",
    "# Helper function to run inference on a TFLite model\n",
    "def run_tflite_model(tflite_file, test_image_indices):\n",
    "  global test_images\n",
    "\n",
    "  # Initialize the interpreter\n",
    "  interpreter = tflite.Interpreter(model_path=str(tflite_file))\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  predictions = np.zeros((len(test_image_indices),), dtype=np.int32)\n",
    "  for i, test_image_index in enumerate(test_image_indices):\n",
    "    test_image = test_images[test_image_index]\n",
    "\n",
    "    # Check if the input type is quantized, then rescale test data to int8\n",
    "    if input_details['dtype'] == tf.int8:\n",
    "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "      # print(input_scale, input_zero_point)\n",
    "      test_image = tf.clip_by_value(tf.round(tf.cast(test_image, dtype=tf.float32) / input_scale) + input_zero_point, clip_value_max=127, clip_value_min=-127)\n",
    "\n",
    "    # print(test_image.shape)\n",
    "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "    # print(test_image.shape)\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to evaluate a TFLite model on all images\n",
    "def evaluate_model(tflite_file, model_type):\n",
    "  global test_images\n",
    "  global test_labels\n",
    "\n",
    "  test_image_indices = range(test_images.shape[0])\n",
    "  predictions = run_tflite_model(tflite_file, test_image_indices)\n",
    "\n",
    "  accuracy = (np.sum(test_labels== predictions) * 100) / len(test_images)\n",
    "\n",
    "  print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (\n",
    "      model_type, accuracy, len(test_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(tflite_model_quant_file, model_type=\"Int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "tflite_interpreter = tf.lite.Interpreter(model_path='../saved_models/lenet5_int8.tflite')\n",
    "tflite_interpreter.allocate_tensors()\n",
    "\n",
    "tensor_details = tflite_interpreter.get_tensor_details()\n",
    "num_fc_layers = 2\n",
    "num_conv2d_layers = 3\n",
    "\n",
    "obj = []\n",
    "cache = []\n",
    "\n",
    "for dict in tensor_details:\n",
    "    # print(dict)\n",
    "    i = dict['index']\n",
    "    name = dict['name']\n",
    "    shape = dict['shape']\n",
    "    if ';' not in name:\n",
    "        if 'BiasAdd' in name:\n",
    "            bias = tflite_interpreter.tensor(i)()\n",
    "            # print(i, name, shape)\n",
    "            # print(bias)\n",
    "        if 'MatMul' in name:\n",
    "            weights = tflite_interpreter.tensor(i)()\n",
    "            reshaped_weights = np.transpose(weights)\n",
    "            # print(i, name, reshaped_weights.shape)\n",
    "            # print(reshaped_weights)\n",
    "            cache = {'fc' + str(num_fc_layers) + '.weights': reshaped_weights, 'fc' + str(num_fc_layers) + '.bias': bias}\n",
    "            obj.append(cache)\n",
    "            num_fc_layers -= 1\n",
    "        if name.split('/')[-1] == 'Conv2D':\n",
    "            weights = tflite_interpreter.tensor(i)()\n",
    "            # if num_conv2d_layers == 2:\n",
    "            #     print(i, name, weights.shape)\n",
    "            #     print(weights)\n",
    "            reshaped_weights = np.zeros(dtype=np.int8, shape=(weights.shape[0], weights.shape[3], weights.shape[2], weights.shape[1]))\n",
    "            for l in range(weights.shape[0]):\n",
    "                for k in range(weights.shape[1]):\n",
    "                    for j in range(weights.shape[2]):\n",
    "                        for i in range(weights.shape[3]):\n",
    "                            reshaped_weights[l][i][k][j] = weights[l][k][j][i]\n",
    "            \n",
    "            # if num_conv2d_layers == 2:\n",
    "            #     print(i, name, reshaped_weights.shape)\n",
    "            #     print(reshaped_weights)\n",
    "            cache = {'conv' + str(num_conv2d_layers) + '.weights': reshaped_weights, 'conv' + str(num_conv2d_layers) + '.bias': bias}\n",
    "            obj.append(cache)\n",
    "            num_conv2d_layers -= 1\n",
    "\n",
    "with open('./params.pkl', 'wb') as handle:\n",
    "    pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./params.pkl', 'rb') as handle:\n",
    "    b = pickle.load(handle)\n",
    "    print(b[4]['conv1.weights'].shape, b[4]['conv1.bias'].shape)\n",
    "    print(b[3]['conv2.weights'].shape, b[3]['conv2.bias'].shape)\n",
    "    print(b[2]['conv3.weights'].shape, b[2]['conv3.bias'].shape)\n",
    "    print(b[1]['fc1.weights'].shape, b[1]['fc1.bias'].shape)\n",
    "    print(b[0]['fc2.weights'].shape, b[0]['fc2.bias'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
