{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tflite\n",
    "!pip install opencv-python\n",
    "!pip install tf-models-official\n",
    "!pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the list of operator names with their corresponding operator indexes from schema.fbs file of Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Path to the schema.fbs file\n",
    "schema_fbs_file = os.path.join(os.getcwd(), \"schema.fbs\")\n",
    "\n",
    "# Function to extract builtin operators from schema.fbs\n",
    "def extract_builtin_operators(schema_fbs_file):\n",
    "    builtin_operators = {}\n",
    "\n",
    "    with open(schema_fbs_file, \"r\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "        # Regex pattern to find enum definitions\n",
    "        enum_pattern = r'enum BuiltinOperator(.*?)}'\n",
    "        enums = re.findall(enum_pattern, content, re.DOTALL)\n",
    "\n",
    "        # Extract enum values and names\n",
    "        for enum in enums:\n",
    "            enum_values = re.findall(r'(\\w+)\\s*=\\s*(-?\\d+)', enum)\n",
    "            for enum_name, enum_value in enum_values:\n",
    "                builtin_operators[int(enum_value)] = enum_name\n",
    "\n",
    "    return builtin_operators\n",
    "\n",
    "# Extract builtin operators\n",
    "builtin_operators = extract_builtin_operators(schema_fbs_file)\n",
    "\n",
    "# Print the dictionary\n",
    "print(\"Builtin Operators Dictionary:\")\n",
    "for enum_value, enum_name in builtin_operators.items():\n",
    "    print(f\"{enum_value}: {enum_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflite.Model import Model\n",
    "from tflite.TensorType import TensorType\n",
    "from tflite.BuiltinOperator import BuiltinOperator\n",
    "\n",
    "def extract_tensor_values(tensor, buffer):\n",
    "  buffer_data = buffer.DataAsNumpy()\n",
    "  tensor_type = tensor.Type()\n",
    "  data_length = buffer.DataLength()\n",
    "  shape = tuple(tensor.ShapeAsNumpy())\n",
    "  # bytes_per_data = 0\n",
    "\n",
    "  # Convert buffer data to a NumPy array based on the datatype\n",
    "  if tensor_type == TensorType.FLOAT32:\n",
    "    buffer_data = np.empty((data_length,), dtype=np.float32)\n",
    "    for i in range(data_length):\n",
    "      buffer_data[i] = buffer.Data(i)\n",
    "    tensor_values = np.frombuffer(buffer_data, dtype=np.float32)\n",
    "    # bytes_per_data = 4\n",
    "  elif tensor_type == TensorType.UINT8:\n",
    "    # print(\"uint8\")\n",
    "    buffer_data = np.empty((data_length,), dtype=np.uint8)\n",
    "    for i in range(data_length):\n",
    "      buffer_data[i] = buffer.Data(i)\n",
    "    tensor_values = np.frombuffer(buffer_data, dtype=np.uint8)\n",
    "    # bytes_per_data = 1\n",
    "  elif tensor_type == TensorType.INT8:\n",
    "    # print(\"int8\")\n",
    "    buffer_data = np.empty((data_length,), dtype=np.uint8)\n",
    "    for i in range(data_length):\n",
    "      buffer_data[i] = buffer.Data(i)\n",
    "    # print(buffer_data)\n",
    "    tensor_values = np.frombuffer(buffer_data.tobytes(), dtype=np.int8)\n",
    "    # bytes_per_data = 1\n",
    "  elif tensor_type == TensorType.INT32:\n",
    "    # print(\"int32\")\n",
    "    buffer_data = np.empty((data_length,), dtype=np.uint8)\n",
    "    for i in range(data_length):\n",
    "      buffer_data[i] = buffer.Data(i)\n",
    "    # print(buffer_data)\n",
    "    tensor_values = np.frombuffer(buffer_data.tobytes(), dtype=np.int32)\n",
    "    # bytes_per_data = 4\n",
    "  else:\n",
    "    raise ValueError(\"Unsupported datatype\")\n",
    "\n",
    "  return tensor_values, shape #, bytes_per_data\n",
    "\n",
    "def extract_quantization_params(tensor):\n",
    "  quantization_data = tensor.Quantization()\n",
    "  return quantization_data.ScaleAsNumpy(), quantization_data.ZeroPointAsNumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_operator_params(model, op_code, tensors):\n",
    "  # num_bytes_tensor = 0\n",
    "  # Extract properties of input and output tensors\n",
    "  op_data = {}\n",
    "  op_data['op_code'] = builtin_operators[op_code]\n",
    "\n",
    "  if op_code == BuiltinOperator().QUANTIZE \\\n",
    "  or op_code == BuiltinOperator().LOGISTIC \\\n",
    "  or op_code == BuiltinOperator().SOFTMAX:\n",
    "    for tensor_idx, tensor in enumerate(tensors):\n",
    "      scale, zero_point = extract_quantization_params(tensor)\n",
    "      if tensor_idx == 0:\n",
    "        op_data['i_scale'] = scale\n",
    "        op_data['i_zero_point'] = zero_point\n",
    "      elif tensor_idx == 1:\n",
    "        op_data['o_scale'] = scale\n",
    "        op_data['o_zero_point'] = zero_point\n",
    "\n",
    "  elif op_code == BuiltinOperator().CONV_2D \\\n",
    "  or op_code == BuiltinOperator().DEPTHWISE_CONV_2D:\n",
    "    for tensor_idx, tensor in enumerate(tensors):\n",
    "      buffer_idx = tensor.Buffer()\n",
    "      buffer = model.Buffers(buffer_idx)\n",
    "      data, shape = extract_tensor_values(tensor, buffer)\n",
    "      scale, zero_point = extract_quantization_params(tensor)\n",
    "      if tensor_idx == 0:\n",
    "        op_data['i_scale'] = scale\n",
    "        op_data['i_zero_point'] = zero_point\n",
    "      elif tensor_idx == 1:\n",
    "        tmp_data = data.reshape(shape)\n",
    "        reshaped_data = np.zeros(dtype=np.int8, shape=(shape[0], shape[3], shape[2], shape[1]))\n",
    "        for l in range(shape[0]):\n",
    "          for k in range(shape[1]):\n",
    "            for j in range(shape[2]):\n",
    "              for i in range(shape[3]):\n",
    "                reshaped_data[l][i][k][j] = tmp_data[l][k][j][i]\n",
    "        op_data['w_data'] = reshaped_data\n",
    "        op_data['w_scale'] = scale\n",
    "        op_data['w_zero_point'] = zero_point\n",
    "      elif tensor_idx == 2:\n",
    "        op_data['b_data'] = data.reshape(shape)\n",
    "        op_data['b_scale'] = scale\n",
    "        op_data['b_zero_point'] = zero_point\n",
    "      elif tensor_idx == 3:\n",
    "        op_data['o_scale'] = scale\n",
    "        op_data['o_zero_point'] = zero_point\n",
    "\n",
    "  elif op_code == BuiltinOperator().FULLY_CONNECTED:\n",
    "    for tensor_idx, tensor in enumerate(tensors):\n",
    "      buffer_idx = tensor.Buffer()\n",
    "      buffer = model.Buffers(buffer_idx)\n",
    "      data, shape = extract_tensor_values(tensor, buffer)\n",
    "      scale, zero_point = extract_quantization_params(tensor)\n",
    "      if tensor_idx == 0:\n",
    "        op_data['i_scale'] = scale\n",
    "        op_data['i_zero_point'] = zero_point\n",
    "      elif tensor_idx == 1:\n",
    "        tmp_data = data.reshape(shape)\n",
    "        reshaped_data = np.transpose(tmp_data)\n",
    "        op_data['w_data'] = reshaped_data\n",
    "        op_data['w_scale'] = scale\n",
    "        op_data['w_zero_point'] = zero_point\n",
    "      elif tensor_idx == 2:\n",
    "        op_data['b_data'] = data.reshape(shape)\n",
    "        op_data['b_scale'] = scale\n",
    "        op_data['b_zero_point'] = zero_point\n",
    "      elif tensor_idx == 3:\n",
    "        op_data['o_scale'] = scale\n",
    "        op_data['o_zero_point'] = zero_point\n",
    "\n",
    "  elif op_code == BuiltinOperator().ADD:\n",
    "    for tensor_idx, tensor in enumerate(tensors):\n",
    "      scale, zero_point = extract_quantization_params(tensor)\n",
    "      if tensor_idx == 0:\n",
    "        op_data['i0_scale'] = scale\n",
    "        op_data['i0_zero_point'] = zero_point\n",
    "      elif tensor_idx == 1:\n",
    "        op_data['i1_scale'] = scale\n",
    "        op_data['i1_zero_point'] = zero_point\n",
    "      elif tensor_idx == 2:\n",
    "        op_data['o_scale'] = scale\n",
    "        op_data['o_zero_point'] = zero_point\n",
    "\n",
    "  elif op_code == BuiltinOperator().MAX_POOL_2D:\n",
    "    pass\n",
    "\n",
    "  elif op_code == BuiltinOperator().PACK:\n",
    "    pass\n",
    "\n",
    "  elif op_code == BuiltinOperator().RESHAPE:\n",
    "    for tensor_idx, tensor in enumerate(tensors):\n",
    "      buffer_idx = tensor.Buffer()\n",
    "      buffer = model.Buffers(buffer_idx)\n",
    "      data, shape = extract_tensor_values(tensor, buffer)\n",
    "      if tensor_idx == 1:\n",
    "        op_data['new_shape'] = data\n",
    "\n",
    "  elif op_code == BuiltinOperator().CONCATENATION:\n",
    "    pass\n",
    "\n",
    "  elif op_code == BuiltinOperator().DEQUANTIZE:\n",
    "    for tensor_idx, tensor in enumerate(tensors):\n",
    "      scale, zero_point = extract_quantization_params(tensor)\n",
    "      if tensor_idx == 0:\n",
    "        op_data['i_scale'] = scale\n",
    "        op_data['i_zero_point'] = zero_point\n",
    "        \n",
    "  elif op_code == BuiltinOperator().CUSTOM:\n",
    "    for tensor_idx, tensor in enumerate(tensors):\n",
    "      buffer_idx = tensor.Buffer()\n",
    "      buffer = model.Buffers(buffer_idx)\n",
    "      data, shape = extract_tensor_values(tensor, buffer)\n",
    "      if tensor_idx == 2:\n",
    "        reshaped_data = np.zeros(dtype=np.float32, shape=(shape[0], shape[1]))\n",
    "        for i in range(shape[0]):\n",
    "          for j in range(shape[1]):\n",
    "            reshaped_data[i][j] = data[i*shape[1] + j]\n",
    "        op_data['anchor'] = reshaped_data\n",
    "  else:\n",
    "    raise ValueError(\"Unsupported op_code\")\n",
    "  \n",
    "  return op_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_graph = []\n",
    "\n",
    "def extract_model_params(model_file):\n",
    "  # num_bytes_op = 0\n",
    "  # Parse the model's flatbuffers\n",
    "  with open(model_file, \"rb\") as f:\n",
    "    model_buf = f.read()\n",
    "\n",
    "  model = Model.GetRootAsModel(model_buf, 0)\n",
    "\n",
    "  # Access operators and buffers\n",
    "  for subgraph_idx in range(model.SubgraphsLength()):\n",
    "    subgraph = model.Subgraphs(subgraph_idx)\n",
    "    # Extract operator details\n",
    "    for op_idx in range(subgraph.OperatorsLength()):\n",
    "      op = subgraph.Operators(op_idx)\n",
    "      op_code_idx = op.OpcodeIndex()\n",
    "      op_code = model.OperatorCodes(op_code_idx).BuiltinCode()\n",
    "      # Extract inputs and outputs\n",
    "      input_tensors = [subgraph.Tensors(op.Inputs(j)) for j in range(0, op.InputsLength())]\n",
    "      output_tensors = [subgraph.Tensors(op.Outputs(j)) for j in range(0, op.OutputsLength())]\n",
    "      op_params = extract_operator_params(model, op_code, input_tensors + output_tensors)\n",
    "      compute_graph.append(op_params)\n",
    "      # print(\"number of bytes per operator:\", num_bytes_op)\n",
    "  # return num_bytes_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"ssd_mobilenetV2_fpnlite_UINT8_AP24.tflite\"\n",
    "# model_file = \"lenet5_int8.tflite\"\n",
    "dataset = \"APtest_resized\"\n",
    "# output = \"lenet5\"\n",
    "tflite_models_dir = pathlib.Path(\"../../pretrained_models\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
    "tflite_model_quant_file = os.path.join(tflite_models_dir, model_file)\n",
    "# dataset_dir = os.path.join(os.path.join(os.getcwd(), \"../../datasets\"), dataset)\n",
    "output_dir = pathlib.Path(os.path.join(os.path.join(os.getcwd(), '../../model_output'), output))\n",
    "output_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_model_params(tflite_model_quant_file)\n",
    "for node in compute_graph:\n",
    "  print(node)\n",
    "# print(f\"total number of bytes required: {num_bytes_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname = 'lenet5.pkl'\n",
    "fname = 'autopolls.pkl'\n",
    "with open(os.path.join(output_dir, fname), 'wb') as handle:\n",
    "    pickle.dump(compute_graph, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for visualizing images with bounding boxes, label and score drawn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata(dir):\n",
    "  in1 = open(os.path.join(dir, \"key\"),'rb')\n",
    "  fKey = pickle.load(in1)\n",
    "  in1.close()\n",
    "  return fKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize an image with bounding boxes from labels\n",
    "def visualize_before_prediction(dir, metadata, fre):\n",
    "  # read in the image\n",
    "  in1 = cv.imread(os.path.join(dir, (metadata[fre]['file_name']).split('/')[-1]))\n",
    "  sz1 = np.shape(in1)\n",
    "  in1 = cv.cvtColor(in1, cv.COLOR_BGR2RGB)\n",
    "  tbox1 = metadata[fre]['bbox']\n",
    "\n",
    "  # overlay the bounding box and save\n",
    "  for ele in tbox1:\n",
    "    cv.rectangle(in1,(int(sz1[1]*ele[0]),int(sz1[0]*ele[1])),(int(sz1[1]*ele[2]),int(sz1[0]*ele[3])),color=(0,0,255),thickness=4)\n",
    "  # cv.imwrite(dir + '/test_' + fre + '.jpg',in1)\n",
    "  plt.imshow(in1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize an image with bounding boxes from prediction\n",
    "def visualize_after_prediction(dir, metadata, fre, bbox):\n",
    "  # read in the image\n",
    "  in1 = cv.imread(os.path.join(dir, (metadata[fre]['file_name']).split('/')[-1]))\n",
    "  sz1 = np.shape(in1)\n",
    "  in1 = cv.cvtColor(in1, cv.COLOR_BGR2RGB)\n",
    "  tbox1 = bbox\n",
    "\n",
    "  # overlay the bounding box and save\n",
    "  for ele in tbox1:\n",
    "    cv.rectangle(in1,(int(sz1[1]*ele[0]),int(sz1[0]*ele[1])),(int(sz1[1]*ele[2]),int(sz1[0]*ele[3])),color=(0,0,255),thickness=4)\n",
    "  # cv.imwrite(dir + '/test_' + str(fre) + '.jpg',in1)\n",
    "  plt.imshow(in1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_category_index(label_path=None):\n",
    "  \"\"\"\n",
    "  To create dictionary of label map\n",
    "  Parameters\n",
    "  ----------\n",
    "  label_path : string, optional\n",
    "      Path to labelmap.txt. The default is None.\n",
    "  Returns\n",
    "  -------\n",
    "  category_index : dict\n",
    "      nested dictionary of labels.\n",
    "  \"\"\"\n",
    "  f = open(label_path)\n",
    "  category_index = {}\n",
    "  for i, val in enumerate(f):\n",
    "      if i != 0:\n",
    "          val = val[:-1]\n",
    "          if val != '???':\n",
    "              category_index.update({(i-1): {'id': (i-1), 'name': val}})\n",
    "          \n",
    "  f.close()\n",
    "  return category_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_nms(output_dict, num_classes=1, iou_thresh=0.5, score_thresh=0.6):\n",
    "    \"\"\"\n",
    "    Function to apply non-maximum suppression on different classes\n",
    "    Parameters\n",
    "    ----------\n",
    "    output_dict : dictionary\n",
    "        dictionary containing:\n",
    "            'detection_boxes' : Bounding boxes coordinates. Shape (N, 4)\n",
    "            'detection_classes' : Class indices detected. Shape (N)\n",
    "            'detection_scores' : Shape (N)\n",
    "            'num_detections' : Total number of detections i.e. N. Shape (1)\n",
    "    iou_thresh : int, optional\n",
    "        Intersection Over Union threshold value. The default is 0.5.\n",
    "    score_thresh : int, optional\n",
    "        Score threshold value below which to ignore. The default is 0.6.\n",
    "    Returns\n",
    "    -------\n",
    "    output_dict : dictionary\n",
    "        dictionary containing only scores and IOU greater than threshold.\n",
    "            'detection_boxes' : Bounding boxes coordinates. Shape (N2, 4)\n",
    "            'detection_classes' : Class indices detected. Shape (N2)\n",
    "            'detection_scores' : Shape (N2)\n",
    "            where N2 is the number of valid predictions after those conditions.\n",
    "    \"\"\"\n",
    "    num_detections = int(output_dict['num_detections'])\n",
    "    boxes = np.zeros([1, num_detections, num_classes, 4])\n",
    "    scores = np.zeros([1, num_detections, num_classes])\n",
    "    # val = [0]*q\n",
    "    for i in range(num_detections):\n",
    "        # indices = np.where(classes == output_dict['detection_classes'][i])[0][0]\n",
    "        boxes[0, i, output_dict['detection_classes'][i], :] = output_dict['detection_boxes'][i]\n",
    "        scores[0, i, output_dict['detection_classes'][i]] = output_dict['detection_scores'][i]\n",
    "    nmsd = tf.image.combined_non_max_suppression(boxes=boxes,\n",
    "                                                 scores=scores,\n",
    "                                                 max_output_size_per_class=1,\n",
    "                                                 max_total_size=num_detections,\n",
    "                                                 iou_threshold=iou_thresh,\n",
    "                                                 score_threshold=score_thresh,\n",
    "                                                 pad_per_class=False,\n",
    "                                                 clip_boxes=False)\n",
    "    valid = nmsd.valid_detections[0].numpy()\n",
    "    output_dict = {\n",
    "                   'detection_boxes' : nmsd.nmsed_boxes[0].numpy()[:valid],\n",
    "                   'detection_classes' : nmsd.nmsed_classes[0].numpy().astype(np.int64)[:valid],\n",
    "                   'detection_scores' : nmsd.nmsed_scores[0].numpy()[:valid],\n",
    "                   }\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "# Helper function to run inference on a TFLite model\n",
    "def run_tflite_model(tflite_file, dataset_dir, output_dir):\n",
    "  # Initialize the interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "  # print(input_details['dtype'])\n",
    "\n",
    "  category_index = create_category_index(label_path=os.path.join(dataset_dir, 'label.txt'))\n",
    "\n",
    "  metadata = extract_metadata(dataset_dir)\n",
    "\n",
    "  for i in range(len(metadata)):\n",
    "    test_image = cv.imread(os.path.join(dataset_dir, (metadata[i]['file_name']).split('/')[-1]))\n",
    "    test_image_expanded = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_image_expanded)\n",
    "    interpreter.invoke()\n",
    "\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    # outputs are:\n",
    "    # - scores\n",
    "    # - bboxes [top, left, bottom, right] normalized 0-1\n",
    "    # - n_boxes (shape 1)\n",
    "    # - classes\n",
    "    assert len(output_details) == 4\n",
    "\n",
    "    # make fake output with shape (n_boxes, 6)\n",
    "    # 6 = [class, score, top, left, bottom, right]\n",
    "    n_boxes = output_details[0]['shape'][1]\n",
    "\n",
    "    # validate output shape\n",
    "    assert tuple(output_details[0]['shape']) == (1, n_boxes)\n",
    "    assert tuple(output_details[1]['shape']) == (1, n_boxes, 4)\n",
    "    assert tuple(output_details[2]['shape']) == (1,)\n",
    "    assert tuple(output_details[3]['shape']) == (1, n_boxes)\n",
    "\n",
    "    scores, bboxes, _, classes = [np.squeeze(interpreter.get_tensor(td['index'])) for td in output_details]\n",
    "\n",
    "    # Adding quantization factors for SSD models\n",
    "    scores = scores*output_details[0]['quantization'][0]\n",
    "    scale, zeropoint = output_details[1]['quantization']\n",
    "    bboxes = (bboxes - zeropoint) * scale\n",
    "    scale, zeropoint = output_details[3]['quantization']\n",
    "    classes = np.round((classes - zeropoint) * scale)\n",
    "\n",
    "    output_dict = {\n",
    "                  'detection_boxes' : bboxes,\n",
    "                  'detection_classes' : classes,\n",
    "                  'detection_scores' : scores,\n",
    "                  'num_detections' : n_boxes\n",
    "                  }\n",
    "\n",
    "    output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
    "\n",
    "    output_dict = apply_nms(output_dict, num_classes=output_details[3]['shape'][0], iou_thresh=0.6, score_thresh=0)\n",
    "\n",
    "    # Visualization of the results of a detection.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "    test_image,\n",
    "    output_dict['detection_boxes'],\n",
    "    output_dict['detection_classes'],\n",
    "    output_dict['detection_scores'],\n",
    "    category_index,\n",
    "    max_boxes_to_draw=1,\n",
    "    use_normalized_coordinates=True,\n",
    "    min_score_thresh=0,\n",
    "    line_thickness=3)\n",
    "    \n",
    "    filename = output_dir + '/' + ((metadata[i]['file_name']).split('/')[-1]).split('.')[0] + 'out.jpg'\n",
    "    cv.imwrite(filename, test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_tflite_model(tflite_model_quant_file, dataset_dir, output_dir)\n",
    "# visualize_before_prediction(dataset_dir, extract_metadata(dataset_dir), 16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
